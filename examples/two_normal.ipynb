{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "This notebook demonstrates how to use causalprog to approximate bounds for a simple problem.\n",
    "\n",
    "For the following distributions\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X &\\sim \\mathcal{N}(\\mu_{x}, 1.0) \\\\\n",
    "Y \\mid X &\\sim \\mathcal{N}(X, \\nu_{y})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "we wish to calculate bounds for the causal estimand\n",
    "\n",
    "$$ \\sigma(\\mu_{x}, \\nu_{y}) = \\mathbb{E}[Y]$$\n",
    "\n",
    "given observed data (constraints)\n",
    "\n",
    "$$ \\phi(\\mu_{x}, \\nu_{y}) = \\mathbb{E}[X]$$\n",
    "\n",
    "and tolerance in the observed data $\\epsilon$.\n",
    "\n",
    "Therefore we aim to solve the following\n",
    "\n",
    "$$ \\mathrm{max}/\\mathrm{min}_{\\mu_{x}, \\nu_{y}} \\mu_{x}, \\quad\n",
    "\\text{subject to } \\vert \\mu_{x} - \\phi_{obs} \\vert \\leq \\epsilon.\n",
    "$$\n",
    "\n",
    "The solution to this is $\\mu_{x}^{*} = \\phi_{obs} \\pm \\epsilon $    \n",
    "The value of $\\nu_{y}$ can be any positive value, since in this\n",
    "setup both $\\phi$ and $\\sigma$ are independent of it.\n",
    "\n",
    "The corresponding Lagrangians are: \n",
    "\n",
    "$$ \\mathcal{L}_{\\min}(\\mu_{x}, \\nu_{y}, \\lambda) =  \\mu_{x}\n",
    "+ \\lambda(|\\mu_{x} - \\phi_{obs}| - \\epsilon) \\qquad \\lambda \\geq 0 $$\n",
    "\n",
    "$$ \\mathcal{L}_{\\max}(\\mu_{x}, \\nu_{y}, \\lambda) = - \\mu_{x}\n",
    "+ \\lambda(|\\mu_{x} - \\phi_{obs}| - \\epsilon) \\qquad \\lambda \\geq 0 $$\n",
    "\n",
    "\n",
    "With KKT (primal-dual) solutions $(\\mu_{x}^*, \\nu_{y}, \\lambda^*) = (\\phi_{obs} \\pm \\epsilon, \\nu_{y}, 1)$\n",
    "\n",
    "In this notebook, with assistance from causalprog, we will attempt to find this solution using the naive approach of minimising  $\\| \\nabla \\mathcal{L} \\|_2^2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Graph\n",
    "\n",
    "Before solving, we must define the problem's corresponding DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalprog.graph import Graph\n",
    "\n",
    "# First initialise the graph\n",
    "graph = Graph(label=\"two_normal_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Nodes\n",
    "For each distribution in the causal graph (`X` and `Y` in our case), add a `DistributionNode`.\n",
    "\n",
    "Then, we must set the parameters for our distributions.\n",
    "\n",
    "### Setting Distribution Parameters\n",
    "\n",
    "1. **Decision Parameters**  \n",
    "e.g. $\\mu_{x}$, $\\nu_{y}$\n",
    "   - Add a `ParameterNode`.  \n",
    "   - Reference it in the `parameters` dictionary of the corresponding `DistributionNode`.\n",
    "\n",
    "2. **Derived Parameters**  \n",
    "e.g. $\\mu_{y}$\n",
    "   - If a parameter is the result of a previous distribution,  \n",
    "     reference the corresponding `DistributionNode` in the `parameters` dictionary.\n",
    "\n",
    "3. **Constant Parameters**  \n",
    "e.g. $\\nu_{x}$\n",
    "   - Set directly in the `constant_parameters` dictionary of the `DistributionNode`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.distributions import Normal\n",
    "\n",
    "from causalprog.graph import DistributionNode, ParameterNode\n",
    "\n",
    "graph.add_node(ParameterNode(label=\"X_mean\"))\n",
    "graph.add_node(\n",
    "    DistributionNode(\n",
    "        distribution=Normal,\n",
    "        label=\"X\",\n",
    "        constant_parameters={\"scale\": 1},  # Set X std to 1\n",
    "        parameters={\"loc\": \"X_mean\"},  # Set X mean as result of ParameterNode X_mean\n",
    "    )\n",
    ")\n",
    "\n",
    "graph.add_node(ParameterNode(label=\"Y_cov\"))\n",
    "graph.add_node(\n",
    "    DistributionNode(\n",
    "        distribution=Normal,\n",
    "        label=\"Y\",\n",
    "        parameters={\n",
    "            \"loc\": \"X\",  # Set Y mean as result of DistributionNode X\n",
    "            \"scale\": \"Y_cov\",  # Set Y std as result of ParameterNode Y_cov\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Edges\n",
    "\n",
    "We must add edges to the graph to define the relationships between nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistributionNode edges\n",
    "graph.add_edge(\"X\", \"Y\")\n",
    "\n",
    "# ParameterNode edges\n",
    "graph.add_edge(\"X_mean\", \"X\")\n",
    "graph.add_edge(\"Y_cov\", \"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Problem\n",
    "\n",
    "We can now use the graph to define the problem we wish to solve.\n",
    "\n",
    "To do so, we define our constraints with `Constraint` and our causal estimand with `CausalEstimand`.  \n",
    "\n",
    "Each `Constraint` requires a function to calculate the constrained quantity, e.g. $\\mu_{x}$, from samples of the graph. In the function, we reference nodes with the labels we assigned previously (\"X\" and \"Y\").  \n",
    "\n",
    "Likewise, each `CausalEstimand` requires a function to calculate the causal estimand, e.g. $\\mu_{y}$, from samples of the graph. Again, we use the labels we assigned previously.\n",
    "\n",
    "We then use our `Constraint` and `CausalEstimand` to define our problem with `CausalProblem`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalprog.causal_problem.causal_problem import CausalProblem\n",
    "from causalprog.causal_problem.components import CausalEstimand, Constraint\n",
    "\n",
    "# Define the constraint using observed data and a tolerance level.\n",
    "PHI_OBSERVED = 0.0\n",
    "EPSILON = 1\n",
    "constraint = Constraint(\n",
    "    model_quantity=lambda **pv: pv[\"X\"].mean(),\n",
    "    data=PHI_OBSERVED,\n",
    "    tolerance=EPSILON,\n",
    ")\n",
    "\n",
    "# Define the causal estimand\n",
    "causal_estimand = CausalEstimand(do_with_samples=lambda **pv: pv[\"Y\"].mean())\n",
    "\n",
    "# Define the problem using the graph, constraint, and causal estimand.\n",
    "causal_problem = CausalProblem(\n",
    "    graph,\n",
    "    constraint,\n",
    "    causal_estimand=causal_estimand,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the bounds of the causal estimand.\n",
    "To do this, we'll seek the stationary points of the Lagrangian, using the naive approach of minimising $\\| \\nabla \\mathcal{L} \\|_2^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy.typing as npt\n",
    "import optax\n",
    "\n",
    "from causalprog.solvers.sgd import stochastic_gradient_descent\n",
    "from causalprog.solvers.solver_callbacks import tqdm_callback\n",
    "from causalprog.solvers.solver_result import SolverResult\n",
    "from causalprog.utils.norms import l2_normsq\n",
    "\n",
    "# Define our initial guess for the decision variables and lagrange multiplier\n",
    "LAGRANGE_MULTIPLIER_INIT = jnp.atleast_1d(0.5)\n",
    "INIT_PARAMS = {\n",
    "    \"X_mean\": 0.0,\n",
    "    \"Y_cov\": 1.0,\n",
    "}\n",
    "\n",
    "# Choose stochastic gradient descent settings\n",
    "RNG_KEY = jax.random.key(42)\n",
    "LEARNING_RATE = 1.0e-1\n",
    "MAX_OPTIMISER_ITER = 200\n",
    "optimiser = optax.adam(LEARNING_RATE)\n",
    "\n",
    "\n",
    "# Define a function to find a bound using a naive Lagrangian approach\n",
    "def naive_lagrangian_approach(maximum_problem: bool) -> SolverResult:\n",
    "    lagrangian = causal_problem.lagrangian(\n",
    "        n_samples=300,\n",
    "        maximum_problem=maximum_problem,\n",
    "    )\n",
    "\n",
    "    # Define the objective function for optimization\n",
    "    # arg x structure should match stochastic_gradient_descent arg initial_guess\n",
    "    def objective(x: npt.ArrayLike, key: jax.Array) -> npt.ArrayLike:\n",
    "        v = jax.grad(lagrangian, argnums=(0, 1))(*x, rng_key=key)\n",
    "        return l2_normsq(v)\n",
    "\n",
    "    # Run the optimisation\n",
    "    return stochastic_gradient_descent(\n",
    "        obj_fn=objective,\n",
    "        initial_guess=(INIT_PARAMS, LAGRANGE_MULTIPLIER_INIT),\n",
    "        fn_kwargs={\"key\": RNG_KEY},\n",
    "        maxiter=MAX_OPTIMISER_ITER,\n",
    "        optimiser=optimiser,\n",
    "        history_logging_interval=1,  # Log optimisation history every iteration\n",
    "        callbacks=tqdm_callback(MAX_OPTIMISER_ITER),  # Add a progress bar\n",
    "    )\n",
    "\n",
    "\n",
    "# Calculate the bounds\n",
    "max_result = naive_lagrangian_approach(maximum_problem=True)\n",
    "min_result = naive_lagrangian_approach(maximum_problem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing the Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `stochastic_gradient_descent` returns a `SolverResult` object. The `SolverResult` stores results and details of the optimisation.  \n",
    "\n",
    "The attributes of `SolverResult` that are most relevant to this example notebook are:\n",
    "\n",
    "- `fn_args`: The objective arguments at the final iteration. \n",
    "- `obj_val`: The objective value at `fn_args`.\n",
    "- `fn_args_history`: The history of `fn_args` at each iteration that the optimisation is logged. \n",
    "- `obj_val_history`: The history of `obj_val` at each iteration that the optimisation is logged. \n",
    "\n",
    "We will use these to define a function that outputs the best results of our solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from causalprog.solvers.solver_result import SolverResult\n",
    "\n",
    "\n",
    "# We define a function to print the results of the SGD runs given the SolverResult\n",
    "def print_sgd_results(result: SolverResult, maximum_problem: bool = True) -> None:\n",
    "    \"\"\"Print the results of the stochastic gradient descent runs.\"\"\"\n",
    "    if maximum_problem:\n",
    "        print(\"-------------Max Bound Results-------------\")\n",
    "    else:\n",
    "        print(\"-------------Min Bound Results-------------\")\n",
    "    mindex = np.argmin(result.obj_val_history)\n",
    "    print(f\"Best Parameters: {result.fn_args_history[mindex][0]}\")\n",
    "    print(f\"Best Lagrange Multiplier: {result.fn_args_history[mindex][1][0]}\")\n",
    "    print(f\"Best Objective Value: {result.obj_val_history[mindex]}\\n\")\n",
    "\n",
    "\n",
    "print_sgd_results(max_result, maximum_problem=True)\n",
    "print_sgd_results(min_result, maximum_problem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the result we found for the minimum bound is incorrect. \n",
    "This is because\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}_{\\min}}{\\partial \\mu_{x}}(\\mu_x, \\nu_y, \\lambda) \n",
    "\\Big|_{\\phi_{\\text{obs}} = 0,\\, \\epsilon = 1}\n",
    "&= 1 + \\lambda \\operatorname{sign}(\\mu_x) \\\\[12pt]\n",
    "\\frac{\\partial \\mathcal{L}_{\\min}}{\\partial \\lambda}(\\mu_x, \\nu_y, \\lambda)\n",
    "\\Big|_{\\phi_{\\text{obs}} = 0,\\, \\epsilon = 1}\n",
    "&= |\\mu_x| - 1\n",
    "\\end{align*}\n",
    "\n",
    "Which means that both \n",
    "$$\n",
    "(\\mu_{x}=1, \\lambda=-1) \\implies \\| \\nabla \\mathcal{L}_{\\min} \\|_2^2 = 0 \\\\[12pt]\n",
    "(\\mu_{x}=-1, \\lambda=1) \\implies \\| \\nabla \\mathcal{L}_{\\min} \\|_2^2 = 0\n",
    "$$\n",
    "\n",
    "Clearly this is not ideal. \n",
    "To combat this, we could retry the search with multiple starting points, select the best one we find and hope it's optimal.\n",
    "\n",
    "Or we could try something else..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recalculating the Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of stochastic gradient descent is that we can customise the objective function to anything we like.  \n",
    "\n",
    "Given that this problem is convex, finite, and satisfies Slater's condition, we can use an objective function that targets the KKT conditions directly.  \n",
    "If these conditions are met, our solution will be optimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "import optax\n",
    "\n",
    "\n",
    "def build_kkt_residual_obj(\n",
    "    cp: CausalProblem,\n",
    "    *,\n",
    "    n_samples: int = 1000,\n",
    "    maximum_problem: bool = False,\n",
    "    alpha: float = 1.0,  # weight: primal feasibility\n",
    "    beta: float = 1.0,  # weight: complementary slackness\n",
    "    gamma: float = 1.0,  # weight: dual feasibility\n",
    ") -> Callable[..., jax.Array]:\n",
    "    lagrangian = cp.lagrangian(n_samples=n_samples, maximum_problem=maximum_problem)\n",
    "\n",
    "    def obj(x: npt.ArrayLike, *, rng_key: jax.Array) -> jax.Array:\n",
    "        params, lam = x\n",
    "        grad_theta, g = jax.grad(lagrangian, argnums=(0, 1))(\n",
    "            params, lam, rng_key=rng_key\n",
    "        )\n",
    "\n",
    "        # 1) Stationarity\n",
    "        stat = l2_normsq(grad_theta)\n",
    "\n",
    "        # 2) Primal feasibility\n",
    "        primal = jnp.sum(jnp.maximum(g, 0.0) ** 2)\n",
    "\n",
    "        # 3) Complementary slackness\n",
    "        fb = jnp.sqrt(lam**2 + g**2) - lam + g  # Fischer-Burmeister\n",
    "        fb = jnp.sum(fb**2)\n",
    "\n",
    "        # 4) Dual feasibility\n",
    "        dual = jnp.sum(jnp.minimum(lam, 0.0) ** 2)\n",
    "\n",
    "        return stat + alpha * primal + beta * fb + gamma * dual\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "ALPHA = 1.0  # Primal feasibility\n",
    "BETA = 1.0  # Complementary slackness\n",
    "GAMMA = 1.0  # Dual feasibility\n",
    "\n",
    "optimiser = optax.adam(0.01)\n",
    "\n",
    "\n",
    "# Define a function to find a bound using the KKT residual approach\n",
    "def kkt_residual_approach(maximum_problem: bool) -> SolverResult:\n",
    "    objective = build_kkt_residual_obj(\n",
    "        causal_problem,\n",
    "        n_samples=200,\n",
    "        maximum_problem=maximum_problem,\n",
    "        alpha=ALPHA,\n",
    "        beta=BETA,\n",
    "        gamma=GAMMA,\n",
    "    )\n",
    "\n",
    "    return stochastic_gradient_descent(\n",
    "        obj_fn=objective,\n",
    "        initial_guess=(INIT_PARAMS, LAGRANGE_MULTIPLIER_INIT),\n",
    "        convergence_criteria=lambda x, _: jnp.abs(x),\n",
    "        fn_kwargs={\"rng_key\": RNG_KEY},\n",
    "        maxiter=1000,\n",
    "        tolerance=1e-5,  # We can set a tolerance for which convergence is successful\n",
    "        optimiser=optimiser,\n",
    "        history_logging_interval=1,\n",
    "        callbacks=[tqdm_callback(1000)],\n",
    "    )\n",
    "\n",
    "\n",
    "max_result = kkt_residual_approach(maximum_problem=True)\n",
    "min_result = kkt_residual_approach(maximum_problem=False)\n",
    "\n",
    "print_sgd_results(max_result, maximum_problem=True)\n",
    "print_sgd_results(min_result, maximum_problem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found the correct bounds! ðŸŽ‰\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
